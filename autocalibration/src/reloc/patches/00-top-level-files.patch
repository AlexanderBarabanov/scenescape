--- /tmp/hloc-latest/README.md	2026-01-16 16:13:56.778591228 -0700
+++ README.md	2026-01-16 16:16:08.540274109 -0700
@@ -1,10 +1,10 @@
 # hloc - the hierarchical localization toolbox
 
-This is `hloc`, a modular toolbox for state-of-the-art 6-DoF visual localization. It implements [Hierarchical Localization](https://arxiv.org/abs/1812.03506), leveraging image retrieval and feature matching, and is fast, accurate, and scalable. This codebase combines and makes easily accessible years of research on image matching and Structure-from-Motion.
+This is `hloc`, a modular toolbox for state-of-the-art 6-DoF visual localization. It implements [Hierarchical Localization](https://arxiv.org/abs/1812.03506), leveraging image retrieval and feature matching, and is fast, accurate, and scalable. This codebase won the indoor/outdoor localization challenges at [CVPR 2020](https://sites.google.com/view/vislocslamcvpr2020/home) and [ECCV 2020](https://sites.google.com/view/ltvl2020/), in combination with [SuperGlue](https://psarlin.com/superglue/), our graph neural network for feature matching.
 
 With `hloc`, you can:
 
-- Reproduce state-of-the-art results on multiple indoor and outdoor visual localization benchmarks
+- Reproduce [our CVPR 2020 winning results](https://www.visuallocalization.net/workshop/cvpr/2020/) on outdoor (Aachen) and indoor (InLoc) datasets
 - Run Structure-from-Motion with SuperPoint+SuperGlue to localize with your own datasets
 - Evaluate your own local features or image retrieval for visual localization
 - Implement new localization pipelines and debug them easily üî•
@@ -16,9 +16,9 @@
 
 ##
 
-## Quick start ‚û°Ô∏è [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Eqoz-uLTCGeEWtH95FZyVs2vI-qkTOWr)
+## Quick start ‚û°Ô∏è [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1MrVs9b8aQYODtOGkoaGNF9Nji3sbCNMQ)
 
-Build 3D maps with Structure-from-Motion and localize any Internet image right from your browser! **You can now run `hloc` and COLMAP in Google Colab with GPU for free.** The notebook [`demo.ipynb`](https://colab.research.google.com/drive/1Eqoz-uLTCGeEWtH95FZyVs2vI-qkTOWr) shows how to run SfM and localization in just a few steps. Try it with your own data and let us know!
+Build 3D maps with Structure-from-Motion and localize any Internet image right from your browser! **You can now run `hloc` and COLMAP in Google Colab with GPU for free.** The notebook [`demo.ipynb`](https://colab.research.google.com/drive/1MrVs9b8aQYODtOGkoaGNF9Nji3sbCNMQ) shows how to run SfM and localization in just a few steps. Try it with your own data and let us know!
 
 ## Installation
 
@@ -33,6 +33,7 @@
 All dependencies are listed in `requirements.txt`. **Starting with `hloc-v1.3`, installing COLMAP is not required anymore.** This repository includes external local features as git submodules ‚Äì don't forget to pull submodules with `git submodule update --init --recursive`.
 
 We also provide a Docker image:
+
 ```bash
 docker build -t hloc:latest .
 docker run -it --rm -p 8888:8888 hloc:latest  # for GPU support, add `--runtime=nvidia`
@@ -43,13 +44,13 @@
 
 The toolbox is composed of scripts, which roughly perform the following steps:
 
-1. Extract local features, like [SuperPoint](https://arxiv.org/abs/1712.07629) or [DISK](https://arxiv.org/abs/2006.13566), for all database and query images
+1. Extract SuperPoint local features for all database and query images
 2. Build a reference 3D SfM model
    1. Find covisible database images, with retrieval or a prior SfM model
-   2. Match these database pairs with [SuperGlue](https://psarlin.com/superglue/) or the faster [LightGlue](https://github.com/cvg/LightGlue)
+   2. Match these database pairs with SuperGlue
    3. Triangulate a new SfM model with COLMAP
 3. Find database images relevant to each query, using retrieval
-4. Match the query images
+4. Match the query images with SuperGlue
 5. Run the localization
 6. Visualize and debug
 
@@ -63,6 +64,7 @@
 - `hloc/pipelines/` : entire pipelines for multiple datasets
 
 `hloc` can be imported as an external package with `import hloc` or called from the command line with:
+
 ```bash
 python -m hloc.name_of_script --arg1 --arg2
 ```
@@ -93,30 +95,31 @@
 
 ## Results
 
-- Supported local feature extractors: [SuperPoint](https://arxiv.org/abs/1712.07629), [DISK](https://arxiv.org/abs/2006.13566), [D2-Net](https://arxiv.org/abs/1905.03561), [SIFT](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf), and [R2D2](https://arxiv.org/abs/1906.06195).
-- Supported feature matchers: [SuperGlue](https://arxiv.org/abs/1911.11763), its faster follow-up [LightGlue](https://github.com/cvg/LightGlue), and nearest neighbor search with ratio test, distance test, and/or mutual check. hloc also supports dense matching with [LoFTR](https://github.com/zju3dv/LoFTR).
-- Supported image retrieval: [NetVLAD](https://arxiv.org/abs/1511.07247), [AP-GeM/DIR](https://github.com/naver/deep-image-retrieval), [OpenIBL](https://github.com/yxgeee/OpenIBL), and [MegaLoc](https://github.com/gmberton/MegaLoc).
+- Supported local feature extractors: [SuperPoint](https://arxiv.org/abs/1712.07629), [D2-Net](https://arxiv.org/abs/1905.03561), [SIFT](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf), and [R2D2](https://arxiv.org/abs/1906.06195).
+- Supported feature matchers: [SuperGlue](https://arxiv.org/abs/1911.11763) and nearest neighbor search with ratio test, distance test, and/or mutual check.
+- Supported image retrieval: [NetVLAD](https://arxiv.org/abs/1511.07247), [AP-GeM/DIR](https://github.com/naver/deep-image-retrieval), and [OpenIBL](https://github.com/yxgeee/OpenIBL).
 
 Using NetVLAD for retrieval, we obtain the following best results:
 
-| Methods                                                      | Aachen day         | Aachen night       | Retrieval      |
-| ------------------------------------------------------------ | ------------------ | ------------------ | -------------- |
+| Methods                                                                     | Aachen day         | Aachen night       | Retrieval      |
+| --------------------------------------------------------------------------- | ------------------ | ------------------ | -------------- |
 | [SuperPoint + SuperGlue](https://www.visuallocalization.net/details/10931/) | 89.6 / 95.4 / 98.8 | 86.7 / 93.9 / 100  | NetVLAD top 50 |
-| [SuperPoint + NN](https://www.visuallocalization.net/details/10866/) | 85.4 / 93.3 / 97.2 | 75.5 / 86.7 / 92.9 | NetVLAD top 30 |
-| D2Net (SS) + NN                                              | 84.6 / 91.4 / 97.1 | 83.7 / 90.8 / 100  | NetVLAD top 30 |
+| [SuperPoint + NN](https://www.visuallocalization.net/details/10866/)        | 85.4 / 93.3 / 97.2 | 75.5 / 86.7 / 92.9 | NetVLAD top 30 |
+| D2Net (SS) + NN                                                             | 84.6 / 91.4 / 97.1 | 83.7 / 90.8 / 100  | NetVLAD top 30 |
 
-| Methods                                                      | InLoc DUC1         | InLoc DUC2         | Retrieval      |
-| ------------------------------------------------------------ | ------------------ | ------------------ | -------------- |
-| [SuperPoint + SuperGlue](https://www.visuallocalization.net/details/10936/) | 46.5 / 65.7 / 78.3 | 52.7 / 72.5 / 79.4 | NetVLAD top 40 |
+| Methods                                                                                | InLoc DUC1         | InLoc DUC2         | Retrieval      |
+| -------------------------------------------------------------------------------------- | ------------------ | ------------------ | -------------- |
+| [SuperPoint + SuperGlue](https://www.visuallocalization.net/details/10936/)            | 46.5 / 65.7 / 78.3 | 52.7 / 72.5 / 79.4 | NetVLAD top 40 |
 | [SuperPoint + SuperGlue (temporal)](https://www.visuallocalization.net/details/10937/) | 49.0 / 68.7 / 80.8 | 53.4 / 77.1 / 82.4 | NetVLAD top 40 |
-| [SuperPoint + NN](https://www.visuallocalization.net/details/10896/) | 39.9 / 55.6 / 67.2 | 37.4 / 57.3 / 70.2 | NetVLAD top 20 |
-| D2Net (SS) + NN                                              | 39.9 / 57.6 / 67.2 | 36.6 / 53.4 / 61.8 | NetVLAD top 20 |
+| [SuperPoint + NN](https://www.visuallocalization.net/details/10896/)                   | 39.9 / 55.6 / 67.2 | 37.4 / 57.3 / 70.2 | NetVLAD top 20 |
+| D2Net (SS) + NN                                                                        | 39.9 / 57.6 / 67.2 | 36.6 / 53.4 / 61.8 | NetVLAD top 20 |
 
 Check out [visuallocalization.net/benchmark](https://www.visuallocalization.net/benchmark) for more details and additional baselines.
 
 ## Supported datasets
 
 We provide in [`hloc/pipelines/`](./hloc/pipelines) scripts to run the reconstruction and the localization on the following datasets: Aachen Day-Night (v1.0 and v1.1), InLoc, Extended CMU Seasons, RobotCar Seasons, 4Seasons, Cambridge Landmarks, and 7-Scenes. For example, after downloading the dataset [with the instructions given here](./hloc/pipelines/Aachen#installation), we can run the Aachen Day-Night pipeline with SuperPoint+SuperGlue using the command:
+
 ```bash
 python -m hloc.pipelines.Aachen.pipeline [--outputs ./outputs/aachen]
 ```
@@ -154,7 +157,7 @@
 <details>
 <summary>[Click to expand]</summary>
 
-Each localization run generates a pickle log file. For each query, it contains the selected database images, their matches, and information from the pose solver, such as RANSAC inliers. It can thus be parsed to gather statistics and analyze failure modes or difficult scenarios. 
+Each localization run generates a pickle log file. For each query, it contains the selected database images, their matches, and information from the pose solver, such as RANSAC inliers. It can thus be parsed to gather statistics and analyze failure modes or difficult scenarios.
 
 We also provide some visualization tools in [`hloc/visualization.py`](./hloc/visualization.py) to visualize some attributes of the 3D SfM model, such as visibility of the keypoints, their track length, or estimated sparse depth (like below).
 
@@ -175,6 +178,7 @@
 In a feature file, each key corresponds to the relative path of an image w.r.t. the dataset root (e.g. `db/1.jpg` for Aachen), and has one dataset per prediction (e.g. `keypoints` and `descriptors`, with shape Nx2 and DxN).
 
 In a match file, each key corresponds to the string `path0.replace('/', '-')+'_'+path1.replace('/', '-')` and has a dataset `matches0` with shape N. It indicates, for each keypoint in the first image, the index of the matching keypoint in the second image, or `-1` if the keypoint is unmatched.
+
 </details>
 
 ### Using your own image retrieval
@@ -183,57 +187,12 @@
 <summary>[Click to expand]</summary>
 
 `hloc` also provides an interface for image retrieval via `hloc/extract_features.py`. As previously, simply add a new interface to [`hloc/extractors/`](hloc/extractors/). Alternatively, you will need to export the global descriptors into an HDF5 file, in which each key corresponds to the relative path of an image w.r.t. the dataset root, and contains a dataset `global_descriptor` with size D. You can then export the images pairs with [`hloc/pairs_from_retrieval.py`](hloc/pairs_from_retrieval.py).
-</details>
-
-### Reconstruction with known camera parameters
-
-<details>
-<summary>[Click to expand]</summary>
-
-If the calibration of the camera is known, for example from an external calibration system, you can tell hloc to use these parameters instead of estimating them from EXIF. The name of the camera models and their parameters are [defined by COLMAP](https://colmap.github.io/cameras.html). Python API:
-```python
-opts = dict(camera_model='SIMPLE_RADIAL', camera_params=','.join(map(str, (f, cx, cy, k))))
-model = reconstruction.main(..., image_options=opts)
-```
-Command-line interface:
-```bash
-python -m hloc.reconstruction [...] --image_options camera_model='"SIMPLE_RADIAL"' camera_params='"256,256,256,0"'
-```
-
-By default, hloc refines the camera parameters during the reconstruction process. To prevent this, add:
-```python
-reconstruction.main(..., mapper_options=dict(ba_refine_focal_length=False, ba_refine_extra_params=False))
-```
-```bash
-python -m hloc.reconstruction [...] --mapper_options ba_refine_focal_length=False ba_refine_extra_params=False
-```
 
 </details>
 
 ## Versions
 
 <details>
-<summary>v1.4 (July 2023)</summary>
-
-- New front ends
-  - global features: OpenIBL (https://github.com/cvg/Hierarchical-Localization/pull/164), CosPlace (https://github.com/cvg/Hierarchical-Localization/pull/257)
-  - patch descriptors: SOSNet (https://github.com/cvg/Hierarchical-Localization/pull/161), HardNet (https://github.com/cvg/Hierarchical-Localization/pull/235)
-  - detector & descriptor: DISK (https://github.com/cvg/Hierarchical-Localization/pull/233, https://github.com/cvg/Hierarchical-Localization/pull/291)
-  - sparse matching: AdaLAM (https://github.com/cvg/Hierarchical-Localization/pull/229), LightGlue (https://github.com/cvg/Hierarchical-Localization/pull/285)
-  - dense matching: LoFTR (https://github.com/cvg/Hierarchical-Localization/pull/173, https://github.com/cvg/Hierarchical-Localization/pull/243, https://github.com/cvg/Hierarchical-Localization/pull/254)
-- Triangulation: use known camera poses for two-view geometric verification (https://github.com/cvg/Hierarchical-Localization/pull/178)
-- Control over COLMAP import and reconstruction options (https://github.com/cvg/Hierarchical-Localization/pull/210)
-- Performance
-  - More reliably skip existing pairs in a match file (https://github.com/cvg/Hierarchical-Localization/pull/159)
-  - Faster HDF5 write (https://github.com/cvg/Hierarchical-Localization/pull/194)
-  - Parallel reading and writing in match_features (https://github.com/cvg/Hierarchical-Localization/pull/242)
-- Add scalar detection uncertainty for LaMAR (https://github.com/cvg/Hierarchical-Localization/pull/158)
-- Documentation (https://github.com/cvg/Hierarchical-Localization/pull/294)
-- Updated requirements: tqdm>=4.36.0, pycolmap>=0.3.0, kornia>=0.6.11
-
-</details>
-
-<details>
 <summary>v1.3 (January 2022)</summary>
 
 - Demo notebook in Google Colab
@@ -273,6 +232,7 @@
 <summary>v1.0 (July 2020)</summary>
 
 Initial public version.
+
 </details>
 
 ## Contributions welcome!
--- /tmp/hloc-latest/requirements.txt	2026-01-16 16:13:56.852282750 -0700
+++ requirements.txt	2026-01-16 16:16:08.541281242 -0700
@@ -1,13 +1,16 @@
+# SPDX-FileCopyrightText: (C) 2025 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
+# This file is licensed under Apache 2.0 License.
+
-torch>=1.1
-torchvision>=0.3
+torch==2.8.0
+torchvision==0.23.0
-numpy
-opencv-python
+numpy==1.26.4
+opencv-python-headless==4.11.0.86
-tqdm>=4.36.0
+tqdm==4.67.1
-matplotlib
-plotly
-scipy
-h5py
-pycolmap>=3.13.0
-kornia>=0.6.11
-gdown
+matplotlib==3.9.2
+plotly==6.5.2
+scipy==1.15.3
+h5py==3.11.0
+pycolmap==0.6.0
+kornia==0.8.1
+gdown==5.2.0
-lightglue @ git+https://github.com/cvg/LightGlue

--- /tmp/hloc-latest/setup.py	2026-01-16 16:13:56.852282750 -0700
+++ setup.py	2026-01-16 16:16:08.541355631 -0700
@@ -1,3 +1,6 @@
+# SPDX-FileCopyrightText: (C) 2025 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
+
 from pathlib import Path
 from setuptools import setup, find_packages
 
@@ -5,11 +8,11 @@
 
 root = Path(__file__).parent
 with open(str(root / 'README.md'), 'r', encoding='utf-8') as f:
-    readme = f.read()
+  readme = f.read()
 with open(str(root / 'hloc/__init__.py'), 'r') as f:
-    version = eval(f.read().split('__version__ = ')[1].split()[0])
+  version = eval(f.read().split('__version__ = ')[1].split()[0])
 with open(str(root / 'requirements.txt'), 'r') as f:
-    dependencies = f.read().split('\n')
+  dependencies = f.read().split('\n')
 
 setup(
     name='hloc',
