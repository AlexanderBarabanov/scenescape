diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/4Seasons/localize.py hloc/pipelines/4Seasons/localize.py
--- /tmp/hloc-latest/hloc/pipelines/4Seasons/localize.py	2026-01-16 16:13:56.814548664 -0700
+++ hloc/pipelines/4Seasons/localize.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,89 +0,0 @@
-import argparse
-from pathlib import Path
-
-from ... import extract_features, localize_sfm, logger, match_features
-from .utils import (
-    delete_unused_images,
-    evaluate_submission,
-    generate_localization_pairs,
-    generate_query_lists,
-    get_timestamps,
-    prepare_submission,
-)
-
-relocalization_files = {
-    "training": "RelocalizationFilesTrain//relocalizationFile_recording_2020-03-24_17-36-22.txt",  # noqa: E501
-    "validation": "RelocalizationFilesVal/relocalizationFile_recording_2020-03-03_12-03-23.txt",  # noqa: E501
-    "test0": "RelocalizationFilesTest/relocalizationFile_recording_2020-03-24_17-45-31_*.txt",  # noqa: E501
-    "test1": "RelocalizationFilesTest/relocalizationFile_recording_2020-04-23_19-37-00_*.txt",  # noqa: E501
-}
-
-parser = argparse.ArgumentParser()
-parser.add_argument(
-    "--sequence",
-    type=str,
-    required=True,
-    choices=["training", "validation", "test0", "test1"],
-    help="Sequence to be relocalized.",
-)
-parser.add_argument(
-    "--dataset",
-    type=Path,
-    default="datasets/4Seasons",
-    help="Path to the dataset, default: %(default)s",
-)
-parser.add_argument(
-    "--outputs",
-    type=Path,
-    default="outputs/4Seasons",
-    help="Path to the output directory, default: %(default)s",
-)
-args = parser.parse_args()
-sequence = args.sequence
-
-data_dir = args.dataset
-ref_dir = data_dir / "reference"
-assert ref_dir.exists(), f"{ref_dir} does not exist"
-seq_dir = data_dir / sequence
-assert seq_dir.exists(), f"{seq_dir} does not exist"
-seq_images = seq_dir / "undistorted_images"
-reloc = ref_dir / relocalization_files[sequence]
-
-output_dir = args.outputs
-output_dir.mkdir(exist_ok=True, parents=True)
-query_list = output_dir / f"{sequence}_queries_with_intrinsics.txt"
-ref_pairs = output_dir / "pairs-db-dist20.txt"
-ref_sfm = output_dir / "sfm_superpoint+superglue"
-results_path = output_dir / f"localization_{sequence}_hloc+superglue.txt"
-submission_dir = output_dir / "submission_hloc+superglue"
-
-num_loc_pairs = 10
-loc_pairs = output_dir / f"pairs-query-{sequence}-dist{num_loc_pairs}.txt"
-
-fconf = extract_features.confs["superpoint_max"]
-mconf = match_features.confs["superglue"]
-
-# Not all query images that are used for the evaluation
-# To save time in feature extraction, we delete unsused images.
-timestamps = get_timestamps(reloc, 1)
-delete_unused_images(seq_images, timestamps)
-
-# Generate a list of query images with their intrinsics.
-generate_query_lists(timestamps, seq_dir, query_list)
-
-# Generate the localization pairs from the given reference frames.
-generate_localization_pairs(sequence, reloc, num_loc_pairs, ref_pairs, loc_pairs)
-
-# Extract, match, amd localize.
-ffile = extract_features.main(fconf, seq_images, output_dir)
-mfile = match_features.main(mconf, loc_pairs, fconf["output"], output_dir)
-localize_sfm.main(ref_sfm, query_list, loc_pairs, ffile, mfile, results_path)
-
-# Convert the absolute poses to relative poses with the reference frames.
-submission_dir.mkdir(exist_ok=True)
-prepare_submission(results_path, reloc, ref_dir / "poses.txt", submission_dir)
-
-# If not a test sequence: evaluation the localization accuracy
-if "test" not in sequence:
-    logger.info("Evaluating the relocalization submission...")
-    evaluate_submission(submission_dir, reloc)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/4Seasons/prepare_reference.py hloc/pipelines/4Seasons/prepare_reference.py
--- /tmp/hloc-latest/hloc/pipelines/4Seasons/prepare_reference.py	2026-01-16 16:13:56.814548664 -0700
+++ hloc/pipelines/4Seasons/prepare_reference.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,51 +0,0 @@
-import argparse
-from pathlib import Path
-
-from ... import extract_features, match_features, pairs_from_poses, triangulation
-from .utils import build_empty_colmap_model, delete_unused_images, get_timestamps
-
-parser = argparse.ArgumentParser()
-parser.add_argument(
-    "--dataset",
-    type=Path,
-    default="datasets/4Seasons",
-    help="Path to the dataset, default: %(default)s",
-)
-parser.add_argument(
-    "--outputs",
-    type=Path,
-    default="outputs/4Seasons",
-    help="Path to the output directory, default: %(default)s",
-)
-args = parser.parse_args()
-
-ref_dir = args.dataset / "reference"
-assert ref_dir.exists(), f"{ref_dir} does not exist"
-ref_images = ref_dir / "undistorted_images"
-
-output_dir = args.outputs
-output_dir.mkdir(exist_ok=True, parents=True)
-ref_sfm_empty = output_dir / "sfm_reference_empty"
-ref_sfm = output_dir / "sfm_superpoint+superglue"
-
-num_ref_pairs = 20
-ref_pairs = output_dir / f"pairs-db-dist{num_ref_pairs}.txt"
-
-fconf = extract_features.confs["superpoint_max"]
-mconf = match_features.confs["superglue"]
-
-# Only reference images that have a pose are used in the pipeline.
-# To save time in feature extraction, we delete unsused images.
-delete_unused_images(ref_images, get_timestamps(ref_dir / "poses.txt", 0))
-
-# Build an empty COLMAP model containing only camera and images
-# from the provided poses and intrinsics.
-build_empty_colmap_model(ref_dir, ref_sfm_empty)
-
-# Match reference images that are spatially close.
-pairs_from_poses.main(ref_sfm_empty, ref_pairs, num_ref_pairs)
-
-# Extract, match, and triangulate the reference SfM model.
-ffile = extract_features.main(fconf, ref_images, output_dir)
-mfile = match_features.main(mconf, ref_pairs, fconf["output"], output_dir)
-triangulation.main(ref_sfm, ref_sfm_empty, ref_images, ref_pairs, ffile, mfile)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/4Seasons/README.md hloc/pipelines/4Seasons/README.md
--- /tmp/hloc-latest/hloc/pipelines/4Seasons/README.md	2026-01-16 16:13:56.814518791 -0700
+++ hloc/pipelines/4Seasons/README.md	1969-12-31 17:00:00.000000000 -0700
@@ -1,43 +0,0 @@
-# 4Seasons dataset
-
-This pipeline localizes sequences from the [4Seasons dataset](https://arxiv.org/abs/2009.06364) and can reproduce our winning submission to the challenge of the [ECCV 2020 Workshop on Map-based Localization for Autonomous Driving](https://sites.google.com/view/mlad-eccv2020/home).
-
-## Installation
-
-Download the sequences from the [challenge webpage](https://sites.google.com/view/mlad-eccv2020/challenge) and run:
-```bash
-unzip recording_2020-04-07_10-20-32.zip -d datasets/4Seasons/reference
-unzip recording_2020-03-24_17-36-22.zip -d datasets/4Seasons/training
-unzip recording_2020-03-03_12-03-23.zip -d datasets/4Seasons/validation
-unzip recording_2020-03-24_17-45-31.zip -d datasets/4Seasons/test0
-unzip recording_2020-04-23_19-37-00.zip -d datasets/4Seasons/test1
-```
-Note that the provided scripts might modify the dataset files by deleting unused images to speed up the feature extraction
-
-## Pipeline
-
-The process is presented in our workshop talk, whose recording can be found [here](https://youtu.be/M-X6HX1JxYk?t=5245).
-
-We first triangulate a 3D model from the given poses of the reference sequence:
-```bash
-python3 -m hloc.pipelines.4Seasons.prepare_reference
-```
-
-We then relocalize a given sequence:
-```bash
-python3 -m hloc.pipelines.4Seasons.localize --sequence [training|validation|test0|test1]
-```
-
-The final submission files can be found in `outputs/4Seasons/submission_hloc+superglue/`. The script will also evaluate these results if the training or validation sequences are selected.
-
-## Results
-
-We evaluate the localization recall at distance thresholds 0.1m, 0.2m, and 0.5m.
-
-| Methods              | test0                  | test1                  |
-| -------------------- | ---------------------- | ---------------------- |
-| **hloc + SuperGlue**     | **91.8 / 97.7 / 99.2**     | **67.3 / 93.5 / 98.7**     |
-| Baseline SuperGlue   | 21.2 / 33.9 / 60.0     | 12.4 / 26.5 / 54.4     |
-| Baseline R2D2        | 21.5 / 33.1 / 53.0     | 12.3 / 23.7 / 42.0     |
-| Baseline D2Net       | 12.5 / 29.3 / 56.7     | 7.5 / 21.4 / 47.7      |
-| Baseline SuperPoint  | 15.5 / 27.5 / 47.5     | 9.0 / 19.4 / 36.4      |
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/4Seasons/utils.py hloc/pipelines/4Seasons/utils.py
--- /tmp/hloc-latest/hloc/pipelines/4Seasons/utils.py	2026-01-16 16:13:56.814548664 -0700
+++ hloc/pipelines/4Seasons/utils.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,231 +0,0 @@
-import glob
-import logging
-import os
-from pathlib import Path
-
-import numpy as np
-
-from ...utils.parsers import parse_retrieval
-from ...utils.read_write_model import (
-    Camera,
-    Image,
-    qvec2rotmat,
-    rotmat2qvec,
-    write_model,
-)
-
-logger = logging.getLogger(__name__)
-
-
-def get_timestamps(files, idx):
-    """Extract timestamps from a pose or relocalization file."""
-    lines = []
-    for p in files.parent.glob(files.name):
-        with open(p) as f:
-            lines += f.readlines()
-    timestamps = set()
-    for line in lines:
-        line = line.rstrip("\n")
-        if line[0] == "#" or line == "":
-            continue
-        ts = line.replace(",", " ").split()[idx]
-        timestamps.add(ts)
-    return timestamps
-
-
-def delete_unused_images(root, timestamps):
-    """Delete all images in root if they are not contained in timestamps."""
-    images = glob.glob((root / "**/*.png").as_posix(), recursive=True)
-    deleted = 0
-    for image in images:
-        ts = Path(image).stem
-        if ts not in timestamps:
-            os.remove(image)
-            deleted += 1
-    logger.info(f"Deleted {deleted} images in {root}.")
-
-
-def camera_from_calibration_file(id_, path):
-    """Create a COLMAP camera from an MLAD calibration file."""
-    with open(path, "r") as f:
-        data = f.readlines()
-    model, fx, fy, cx, cy = data[0].split()[:5]
-    width, height = data[1].split()
-    assert model == "Pinhole"
-    model_name = "PINHOLE"
-    params = [float(i) for i in [fx, fy, cx, cy]]
-    camera = Camera(
-        id=id_, model=model_name, width=int(width), height=int(height), params=params
-    )
-    return camera
-
-
-def parse_poses(path, colmap=False):
-    """Parse a list of poses in COLMAP or MLAD quaternion convention."""
-    poses = []
-    with open(path) as f:
-        for line in f.readlines():
-            line = line.rstrip("\n")
-            if line[0] == "#" or line == "":
-                continue
-            data = line.replace(",", " ").split()
-            ts, p = data[0], np.array(data[1:], float)
-            if colmap:
-                q, t = np.split(p, [4])
-            else:
-                t, q = np.split(p, [3])
-                q = q[[3, 0, 1, 2]]  # xyzw to wxyz
-            R = qvec2rotmat(q)
-            poses.append((ts, R, t))
-    return poses
-
-
-def parse_relocalization(path, has_poses=False):
-    """Parse a relocalization file, possibly with poses."""
-    reloc = []
-    with open(path) as f:
-        for line in f.readlines():
-            line = line.rstrip("\n")
-            if line[0] == "#" or line == "":
-                continue
-            data = line.replace(",", " ").split()
-            out = data[:2]  # ref_ts, q_ts
-            if has_poses:
-                assert len(data) == 9
-                t, q = np.split(np.array(data[2:], float), [3])
-                q = q[[3, 0, 1, 2]]  # xyzw to wxyz
-                R = qvec2rotmat(q)
-                out += [R, t]
-            reloc.append(out)
-    return reloc
-
-
-def build_empty_colmap_model(root, sfm_dir):
-    """Build a COLMAP model with images and cameras only."""
-    calibration = "Calibration/undistorted_calib_{}.txt"
-    cam0 = camera_from_calibration_file(0, root / calibration.format(0))
-    cam1 = camera_from_calibration_file(1, root / calibration.format(1))
-    cameras = {0: cam0, 1: cam1}
-
-    T_0to1 = np.loadtxt(root / "Calibration/undistorted_calib_stereo.txt")
-    poses = parse_poses(root / "poses.txt")
-    images = {}
-    id_ = 0
-    for ts, R_cam0_to_w, t_cam0_to_w in poses:
-        R_w_to_cam0 = R_cam0_to_w.T
-        t_w_to_cam0 = -(R_w_to_cam0 @ t_cam0_to_w)
-
-        R_w_to_cam1 = T_0to1[:3, :3] @ R_w_to_cam0
-        t_w_to_cam1 = T_0to1[:3, :3] @ t_w_to_cam0 + T_0to1[:3, 3]
-
-        for idx, (R_w_to_cam, t_w_to_cam) in enumerate(
-            zip([R_w_to_cam0, R_w_to_cam1], [t_w_to_cam0, t_w_to_cam1])
-        ):
-            image = Image(
-                id=id_,
-                qvec=rotmat2qvec(R_w_to_cam),
-                tvec=t_w_to_cam,
-                camera_id=idx,
-                name=f"cam{idx}/{ts}.png",
-                xys=np.zeros((0, 2), float),
-                point3D_ids=np.full(0, -1, int),
-            )
-            images[id_] = image
-            id_ += 1
-
-    sfm_dir.mkdir(exist_ok=True, parents=True)
-    write_model(cameras, images, {}, path=str(sfm_dir), ext=".bin")
-
-
-def generate_query_lists(timestamps, seq_dir, out_path):
-    """Create a list of query images with intrinsics from timestamps."""
-    cam0 = camera_from_calibration_file(
-        0, seq_dir / "Calibration/undistorted_calib_0.txt"
-    )
-    intrinsics = [cam0.model, cam0.width, cam0.height] + cam0.params
-    intrinsics = [str(p) for p in intrinsics]
-    data = map(lambda ts: " ".join([f"cam0/{ts}.png"] + intrinsics), timestamps)
-    with open(out_path, "w") as f:
-        f.write("\n".join(data))
-
-
-def generate_localization_pairs(sequence, reloc, num, ref_pairs, out_path):
-    """Create the matching pairs for the localization.
-    We simply lookup the corresponding reference frame
-    and extract its `num` closest frames from the existing pair list.
-    """
-    if "test" in sequence:
-        # hard pairs will be overwritten by easy ones if available
-        relocs = [str(reloc).replace("*", d) for d in ["hard", "moderate", "easy"]]
-    else:
-        relocs = [reloc]
-    query_to_ref_ts = {}
-    for reloc in relocs:
-        with open(reloc, "r") as f:
-            for line in f.readlines():
-                line = line.rstrip("\n")
-                if line[0] == "#" or line == "":
-                    continue
-                ref_ts, q_ts = line.split()[:2]
-                query_to_ref_ts[q_ts] = ref_ts
-
-    ts_to_name = "cam0/{}.png".format
-    ref_pairs = parse_retrieval(ref_pairs)
-    loc_pairs = []
-    for q_ts, ref_ts in query_to_ref_ts.items():
-        ref_name = ts_to_name(ref_ts)
-        selected = [ref_name] + ref_pairs[ref_name][: num - 1]
-        loc_pairs.extend([" ".join((ts_to_name(q_ts), s)) for s in selected])
-    with open(out_path, "w") as f:
-        f.write("\n".join(loc_pairs))
-
-
-def prepare_submission(results, relocs, poses_path, out_dir):
-    """Obtain relative poses from estimated absolute and reference poses."""
-    gt_poses = parse_poses(poses_path)
-    all_T_ref0_to_w = {ts: (R, t) for ts, R, t in gt_poses}
-
-    pred_poses = parse_poses(results, colmap=True)
-    all_T_w_to_q0 = {Path(name).stem: (R, t) for name, R, t in pred_poses}
-
-    for reloc in relocs.parent.glob(relocs.name):
-        relative_poses = []
-        reloc_ts = parse_relocalization(reloc)
-        for ref_ts, q_ts in reloc_ts:
-            R_w_to_q0, t_w_to_q0 = all_T_w_to_q0[q_ts]
-            R_ref0_to_w, t_ref0_to_w = all_T_ref0_to_w[ref_ts]
-
-            R_ref0_to_q0 = R_w_to_q0 @ R_ref0_to_w
-            t_ref0_to_q0 = R_w_to_q0 @ t_ref0_to_w + t_w_to_q0
-
-            tvec = t_ref0_to_q0.tolist()
-            qvec = rotmat2qvec(R_ref0_to_q0)[[1, 2, 3, 0]]  # wxyz to xyzw
-
-            out = [ref_ts, q_ts] + list(map(str, tvec)) + list(map(str, qvec))
-            relative_poses.append(" ".join(out))
-
-        out_path = out_dir / reloc.name
-        with open(out_path, "w") as f:
-            f.write("\n".join(relative_poses))
-        logger.info(f"Submission file written to {out_path}.")
-
-
-def evaluate_submission(submission_dir, relocs, ths=[0.1, 0.2, 0.5]):
-    """Compute the relocalization recall from predicted and ground truth poses."""
-    for reloc in relocs.parent.glob(relocs.name):
-        poses_gt = parse_relocalization(reloc, has_poses=True)
-        poses_pred = parse_relocalization(submission_dir / reloc.name, has_poses=True)
-        poses_pred = {(ref_ts, q_ts): (R, t) for ref_ts, q_ts, R, t in poses_pred}
-
-        error = []
-        for ref_ts, q_ts, R_gt, t_gt in poses_gt:
-            R, t = poses_pred[(ref_ts, q_ts)]
-            e = np.linalg.norm(t - t_gt)
-            error.append(e)
-
-        error = np.array(error)
-        recall = [np.mean(error <= th) for th in ths]
-        s = f"Relocalization evaluation {submission_dir.name}/{reloc.name}\n"
-        s += " / ".join([f"{th:>7}m" for th in ths]) + "\n"
-        s += " / ".join([f"{100*r:>7.3f}%" for r in recall])
-        logger.info(s)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/7Scenes/create_gt_sfm.py hloc/pipelines/7Scenes/create_gt_sfm.py
--- /tmp/hloc-latest/hloc/pipelines/7Scenes/create_gt_sfm.py	2026-01-16 16:13:56.814693688 -0700
+++ hloc/pipelines/7Scenes/create_gt_sfm.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,148 +0,0 @@
-from pathlib import Path
-
-import numpy as np
-import PIL.Image
-import pycolmap
-import torch
-from tqdm import tqdm
-
-from ...utils.read_write_model import read_model, write_model
-
-
-def scene_coordinates(p2D, R_w2c, t_w2c, depth, camera):
-    assert len(depth) == len(p2D)
-    pycolmap_camera = pycolmap.Camera(
-        camera_id=camera.id,
-        model=camera.model,
-        width=camera.width,
-        height=camera.height,
-        params=camera.params,
-    )
-    p2D_norm = pycolmap_camera.cam_from_img(p2D)
-    p2D_h = np.concatenate([p2D_norm, np.ones_like(p2D_norm[:, :1])], 1)
-    p3D_c = p2D_h * depth[:, None]
-    p3D_w = (p3D_c - t_w2c) @ R_w2c
-    return p3D_w
-
-
-def interpolate_depth(depth, kp):
-    h, w = depth.shape
-    kp = kp / np.array([[w - 1, h - 1]]) * 2 - 1
-    assert np.all(kp > -1) and np.all(kp < 1)
-    depth = torch.from_numpy(depth)[None, None]
-    kp = torch.from_numpy(kp)[None, None]
-    grid_sample = torch.nn.functional.grid_sample
-
-    # To maximize the number of points that have depth:
-    # do bilinear interpolation first and then nearest for the remaining points
-    interp_lin = grid_sample(depth, kp, align_corners=True, mode="bilinear")[0, :, 0]
-    interp_nn = torch.nn.functional.grid_sample(
-        depth, kp, align_corners=True, mode="nearest"
-    )[0, :, 0]
-    interp = torch.where(torch.isnan(interp_lin), interp_nn, interp_lin)
-    valid = ~torch.any(torch.isnan(interp), 0)
-
-    interp_depth = interp.T.numpy().flatten()
-    valid = valid.numpy()
-    return interp_depth, valid
-
-
-def image_path_to_rendered_depth_path(image_name):
-    parts = image_name.split("/")
-    name = "_".join(["".join(parts[0].split("-")), parts[1]])
-    name = name.replace("color", "pose")
-    name = name.replace("png", "depth.tiff")
-    return name
-
-
-def project_to_image(p3D, R, t, camera, eps: float = 1e-4, pad: int = 1):
-    p3D = (p3D @ R.T) + t
-    visible = p3D[:, -1] >= eps  # keep points in front of the camera
-    p2D_norm = p3D[:, :-1] / p3D[:, -1:].clip(min=eps)
-    pycolmap_camera = pycolmap.Camera(
-        camera_id=camera.id,
-        model=camera.model,
-        width=camera.width,
-        height=camera.height,
-        params=camera.params,
-    )
-    p2D = pycolmap_camera.img_from_cam(p2D_norm)
-    size = np.array([camera.width - pad - 1, camera.height - pad - 1])
-    valid = np.all((p2D >= pad) & (p2D <= size), -1)
-    valid &= visible
-    return p2D[valid], valid
-
-
-def correct_sfm_with_gt_depth(sfm_path, depth_folder_path, output_path):
-    cameras, images, points3D = read_model(sfm_path)
-    for imgid, img in tqdm(images.items()):
-        image_name = img.name
-        depth_name = image_path_to_rendered_depth_path(image_name)
-
-        depth = PIL.Image.open(Path(depth_folder_path) / depth_name)
-        depth = np.array(depth).astype("float64")
-        depth = depth / 1000.0  # mm to meter
-        depth[(depth == 0.0) | (depth > 1000.0)] = np.nan
-
-        R_w2c, t_w2c = img.qvec2rotmat(), img.tvec
-        camera = cameras[img.camera_id]
-        p3D_ids = img.point3D_ids
-        p3Ds = np.stack([points3D[i].xyz for i in p3D_ids[p3D_ids != -1]], 0)
-
-        p2Ds, valids_projected = project_to_image(p3Ds, R_w2c, t_w2c, camera)
-        invalid_p3D_ids = p3D_ids[p3D_ids != -1][~valids_projected]
-        interp_depth, valids_backprojected = interpolate_depth(depth, p2Ds)
-        scs = scene_coordinates(
-            p2Ds[valids_backprojected],
-            R_w2c,
-            t_w2c,
-            interp_depth[valids_backprojected],
-            camera,
-        )
-        invalid_p3D_ids = np.append(
-            invalid_p3D_ids,
-            p3D_ids[p3D_ids != -1][valids_projected][~valids_backprojected],
-        )
-        for p3did in invalid_p3D_ids:
-            if p3did == -1:
-                continue
-            else:
-                obs_imgids = points3D[p3did].image_ids
-                invalid_imgids = list(np.where(obs_imgids == img.id)[0])
-                points3D[p3did] = points3D[p3did]._replace(
-                    image_ids=np.delete(obs_imgids, invalid_imgids),
-                    point2D_idxs=np.delete(
-                        points3D[p3did].point2D_idxs, invalid_imgids
-                    ),
-                )
-
-        new_p3D_ids = p3D_ids.copy()
-        sub_p3D_ids = new_p3D_ids[new_p3D_ids != -1]
-        valids = np.ones(np.count_nonzero(new_p3D_ids != -1), dtype=bool)
-        valids[~valids_projected] = False
-        valids[valids_projected] = valids_backprojected
-        sub_p3D_ids[~valids] = -1
-        new_p3D_ids[new_p3D_ids != -1] = sub_p3D_ids
-        img = img._replace(point3D_ids=new_p3D_ids)
-
-        assert len(img.point3D_ids[img.point3D_ids != -1]) == len(
-            scs
-        ), f"{len(scs)}, {len(img.point3D_ids[img.point3D_ids != -1])}"
-        for i, p3did in enumerate(img.point3D_ids[img.point3D_ids != -1]):
-            points3D[p3did] = points3D[p3did]._replace(xyz=scs[i])
-        images[imgid] = img
-
-    output_path.mkdir(parents=True, exist_ok=True)
-    write_model(cameras, images, points3D, output_path)
-
-
-if __name__ == "__main__":
-    dataset = Path("datasets/7scenes")
-    outputs = Path("outputs/7Scenes")
-
-    SCENES = ["chess", "fire", "heads", "office", "pumpkin", "redkitchen", "stairs"]
-    for scene in SCENES:
-        sfm_path = outputs / scene / "sfm_superpoint+superglue"
-        depth_path = dataset / f"depth/7scenes_{scene}/train/depth"
-        output_path = outputs / scene / "sfm_superpoint+superglue+depth"
-        correct_sfm_with_gt_depth(sfm_path, depth_path, output_path)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/7Scenes/pipeline.py hloc/pipelines/7Scenes/pipeline.py
--- /tmp/hloc-latest/hloc/pipelines/7Scenes/pipeline.py	2026-01-16 16:13:56.814693688 -0700
+++ hloc/pipelines/7Scenes/pipeline.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,139 +0,0 @@
-import argparse
-from pathlib import Path
-
-from ... import (
-    extract_features,
-    localize_sfm,
-    logger,
-    match_features,
-    pairs_from_covisibility,
-    triangulation,
-)
-from ..Cambridge.utils import create_query_list_with_intrinsics, evaluate
-from .create_gt_sfm import correct_sfm_with_gt_depth
-from .utils import create_reference_sfm
-
-SCENES = ["chess", "fire", "heads", "office", "pumpkin", "redkitchen", "stairs"]
-
-
-def run_scene(
-    images,
-    gt_dir,
-    retrieval,
-    outputs,
-    results,
-    num_covis,
-    use_dense_depth,
-    depth_dir=None,
-):
-    outputs.mkdir(exist_ok=True, parents=True)
-    ref_sfm_sift = outputs / "sfm_sift"
-    ref_sfm = outputs / "sfm_superpoint+superglue"
-    query_list = outputs / "query_list_with_intrinsics.txt"
-
-    feature_conf = {
-        "output": "feats-superpoint-n4096-r1024",
-        "model": {
-            "name": "superpoint",
-            "nms_radius": 3,
-            "max_keypoints": 4096,
-        },
-        "preprocessing": {
-            "globs": ["*.color.png"],
-            "grayscale": True,
-            "resize_max": 1024,
-        },
-    }
-    matcher_conf = match_features.confs["superglue"]
-    matcher_conf["model"]["sinkhorn_iterations"] = 5
-
-    test_list = gt_dir / "list_test.txt"
-    create_reference_sfm(gt_dir, ref_sfm_sift, test_list)
-    create_query_list_with_intrinsics(gt_dir, query_list, test_list)
-
-    features = extract_features.main(feature_conf, images, outputs, as_half=True)
-
-    sfm_pairs = outputs / f"pairs-db-covis{num_covis}.txt"
-    pairs_from_covisibility.main(ref_sfm_sift, sfm_pairs, num_matched=num_covis)
-    sfm_matches = match_features.main(
-        matcher_conf, sfm_pairs, feature_conf["output"], outputs
-    )
-    if not (use_dense_depth and ref_sfm.exists()):
-        triangulation.main(
-            ref_sfm, ref_sfm_sift, images, sfm_pairs, features, sfm_matches
-        )
-    if use_dense_depth:
-        assert depth_dir is not None
-        ref_sfm_fix = outputs / "sfm_superpoint+superglue+depth"
-        correct_sfm_with_gt_depth(ref_sfm, depth_dir, ref_sfm_fix)
-        ref_sfm = ref_sfm_fix
-
-    loc_matches = match_features.main(
-        matcher_conf, retrieval, feature_conf["output"], outputs
-    )
-
-    localize_sfm.main(
-        ref_sfm,
-        query_list,
-        retrieval,
-        features,
-        loc_matches,
-        results,
-        covisibility_clustering=False,
-        prepend_camera_name=True,
-    )
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument("--scenes", default=SCENES, choices=SCENES, nargs="+")
-    parser.add_argument("--overwrite", action="store_true")
-    parser.add_argument(
-        "--dataset",
-        type=Path,
-        default="datasets/7scenes",
-        help="Path to the dataset, default: %(default)s",
-    )
-    parser.add_argument(
-        "--outputs",
-        type=Path,
-        default="outputs/7scenes",
-        help="Path to the output directory, default: %(default)s",
-    )
-    parser.add_argument("--use_dense_depth", action="store_true")
-    parser.add_argument(
-        "--num_covis",
-        type=int,
-        default=30,
-        help="Number of image pairs for SfM, default: %(default)s",
-    )
-    args = parser.parse_args()
-
-    gt_dirs = args.dataset / "7scenes_sfm_triangulated/{scene}/triangulated"
-    retrieval_dirs = args.dataset / "7scenes_densevlad_retrieval_top_10"
-
-    all_results = {}
-    for scene in args.scenes:
-        logger.info(f'Working on scene "{scene}".')
-        results = (
-            args.outputs
-            / scene
-            / "results_{}.txt".format("dense" if args.use_dense_depth else "sparse")
-        )
-        if args.overwrite or not results.exists():
-            run_scene(
-                args.dataset / scene,
-                Path(str(gt_dirs).format(scene=scene)),
-                retrieval_dirs / f"{scene}_top10.txt",
-                args.outputs / scene,
-                results,
-                args.num_covis,
-                args.use_dense_depth,
-                depth_dir=args.dataset / f"depth/7scenes_{scene}/train/depth",
-            )
-        all_results[scene] = results
-
-    for scene in args.scenes:
-        logger.info(f'Evaluate scene "{scene}".')
-        gt_dir = Path(str(gt_dirs).format(scene=scene))
-        evaluate(gt_dir, all_results[scene], gt_dir / "list_test.txt")
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/7Scenes/README.md hloc/pipelines/7Scenes/README.md
--- /tmp/hloc-latest/hloc/pipelines/7Scenes/README.md	2026-01-16 16:13:56.814548664 -0700
+++ hloc/pipelines/7Scenes/README.md	1969-12-31 17:00:00.000000000 -0700
@@ -1,74 +0,0 @@
-# 7Scenes dataset
-
-## Installation
-
-1.
-Download the images from the [7Scenes project page](https://www.microsoft.com/en-us/research/project/rgb-d-dataset-7-scenes/):
-```bash
-export dataset=datasets/7scenes
-for scene in chess fire heads office pumpkin redkitchen stairs; \
-do wget http://download.microsoft.com/download/2/8/5/28564B23-0828-408F-8631-23B1EFF1DAC8/$scene.zip -P $dataset \
-&& unzip $dataset/$scene.zip -d $dataset && unzip $dataset/$scene/'*.zip' -d $dataset/$scene; done
-```
-2.
-Download the SIFT SfM models and DenseVLAD image pairs, courtesy of Torsten Sattler:
-
-```bash
-function download {
-wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate "https://docs.google.com/uc?export=download&id=$1" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=$1" -O $2 && rm -rf /tmp/cookies.txt
-unzip $2 -d $dataset && rm $2;
-}
-download 1cu6KUR7WHO7G4EO49Qi3HEKU6n_yYDjb $dataset/7scenes_sfm_triangulated.zip
-download 1IbS2vLmxr1N0f3CEnd_wsYlgclwTyvB1 $dataset/7scenes_densevlad_retrieval_top_10.zip
-```
-Alternatively, if you have ```gdown``` installed:
-
-```bash
-gdown 1cu6KUR7WHO7G4EO49Qi3HEKU6n_yYDjb $dataset/7scenes_sfm_triangulated.zip
-gdown 1IbS2vLmxr1N0f3CEnd_wsYlgclwTyvB1 $dataset/7scenes_densevlad_retrieval_top_10.zip
-```
-
-3.
-Download the rendered depth maps, courtesy of Eric Brachmann for [DSAC\*](https://github.com/vislearn/dsacstar):
-```bash
-wget https://heidata.uni-heidelberg.de/api/access/datafile/4037 -O $dataset/7scenes_rendered_depth.tar.gz
-mkdir $dataset/depth/
-tar xzf $dataset/7scenes_rendered_depth.tar.gz -C $dataset/depth/ && rm $dataset/7scenes_rendered_depth.tar.gz
-```
-
-## Pipeline
-
-```bash
-python3 -m hloc.pipelines.7Scenes.pipeline [--use_dense_depth]
-```
-By default, hloc triangulates a sparse point cloud that can be noisy in indoor environements due to image noise and lack of texture. With the flag `--use_dense_depth`, the pipeline improves the accuracy of the sparse point cloud using dense depth maps provided by the dataset. The original depth maps captured by the RGBD sensor are miscalibrated, so we use depth maps rendered from the mesh obtained by fusing the RGBD data.
-
-## Results
-We report the median error in translation/rotation in cm/deg over all scenes:
-| Method \ Scene                  | Chess          | Fire           | Heads          | Office         | Pumpkin        | Kitchen        | Stairs     |
-| ------------------------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | ---------- |
-| Active Search                   | 3/0.87         | **2**/1.01     | **1**/0.82     | 4/1.15         | 7/1.69         | 5/1.72         | 4/**1.01** |
-| DSAC*                           | **2**/1.10     | **2**/1.24     | **1**/1.82     | **3**/1.15     | **4**/1.34     | 4/1.68         | **3**/1.16 |
-| **SuperPoint+SuperGlue** (sfm)  | **2**/0.84     | **2**/0.93     | **1**/**0.74** | **3**/0.92     | 5/1.27         | 4/1.40         | 5/1.47     |
-| **SuperPoint+SuperGlue** (RGBD) | **2**/**0.80** | **2**/**0.77** | **1**/0.79     | **3**/**0.80** | **4**/**1.07** | **3**/**1.13** | 4/1.15     |
-
-## Citation
-Please cite the following paper if you use the 7Scenes dataset:
-```
-@inproceedings{shotton2013scene,
-  title={Scene coordinate regression forests for camera relocalization in {RGB-D} images},
-  author={Shotton, Jamie and Glocker, Ben and Zach, Christopher and Izadi, Shahram and Criminisi, Antonio and Fitzgibbon, Andrew},
-  booktitle={CVPR},
-  year={2013}
-}
-```
-
-Also cite DSAC* if you use dense depth maps with the flag `--use_dense_depth`:
-```
-@article{brachmann2020dsacstar,
-  title={Visual Camera Re-Localization from {RGB} and {RGB-D} Images Using {DSAC}},
-  author={Brachmann, Eric and Rother, Carsten},
-  journal={TPAMI},
-  year={2021}
-}
-```
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/7Scenes/utils.py hloc/pipelines/7Scenes/utils.py
--- /tmp/hloc-latest/hloc/pipelines/7Scenes/utils.py	2026-01-16 16:13:56.814693688 -0700
+++ hloc/pipelines/7Scenes/utils.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,34 +0,0 @@
-import logging
-
-import numpy as np
-
-from hloc.utils.read_write_model import read_model, write_model
-
-logger = logging.getLogger(__name__)
-
-
-def create_reference_sfm(full_model, ref_model, blacklist=None, ext=".bin"):
-    """Create a new COLMAP model with only training images."""
-    logger.info("Creating the reference model.")
-    ref_model.mkdir(exist_ok=True)
-    cameras, images, points3D = read_model(full_model, ext)
-
-    if blacklist is not None:
-        with open(blacklist, "r") as f:
-            blacklist = f.read().rstrip().split("\n")
-
-    images_ref = dict()
-    for id_, image in images.items():
-        if blacklist and image.name in blacklist:
-            continue
-        images_ref[id_] = image
-
-    points3D_ref = dict()
-    for id_, point3D in points3D.items():
-        ref_ids = [i for i in point3D.image_ids if i in images_ref]
-        if len(ref_ids) == 0:
-            continue
-        points3D_ref[id_] = point3D._replace(image_ids=np.array(ref_ids))
-
-    write_model(cameras, images_ref, points3D_ref, ref_model, ".bin")
-    logger.info(f"Kept {len(images_ref)} images out of {len(images)}.")
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Aachen/pipeline.py hloc/pipelines/Aachen/pipeline.py
--- /tmp/hloc-latest/hloc/pipelines/Aachen/pipeline.py	2026-01-16 16:13:56.814789152 -0700
+++ hloc/pipelines/Aachen/pipeline.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,109 +0,0 @@
-import argparse
-from pathlib import Path
-from pprint import pformat
-
-from ... import (
-    colmap_from_nvm,
-    extract_features,
-    localize_sfm,
-    logger,
-    match_features,
-    pairs_from_covisibility,
-    pairs_from_retrieval,
-    triangulation,
-)
-
-
-def run(args):
-    # Setup the paths
-    dataset = args.dataset
-    images = dataset / "images_upright/"
-
-    outputs = args.outputs  # where everything will be saved
-    sift_sfm = outputs / "sfm_sift"  # from which we extract the reference poses
-    reference_sfm = outputs / "sfm_superpoint+superglue"  # the SfM model we will build
-    sfm_pairs = (
-        outputs / f"pairs-db-covis{args.num_covis}.txt"
-    )  # top-k most covisible in SIFT model
-    loc_pairs = (
-        outputs / f"pairs-query-netvlad{args.num_loc}.txt"
-    )  # top-k retrieved by NetVLAD
-    results = outputs / f"Aachen_hloc_superpoint+superglue_netvlad{args.num_loc}.txt"
-
-    # list the standard configurations available
-    logger.info("Configs for feature extractors:\n%s", pformat(extract_features.confs))
-    logger.info("Configs for feature matchers:\n%s", pformat(match_features.confs))
-
-    # pick one of the configurations for extraction and matching
-    retrieval_conf = extract_features.confs["netvlad"]
-    feature_conf = extract_features.confs["superpoint_aachen"]
-    matcher_conf = match_features.confs["superglue"]
-
-    features = extract_features.main(feature_conf, images, outputs)
-
-    colmap_from_nvm.main(
-        dataset / "3D-models/aachen_cvpr2018_db.nvm",
-        dataset / "3D-models/database_intrinsics.txt",
-        dataset / "aachen.db",
-        sift_sfm,
-    )
-    pairs_from_covisibility.main(sift_sfm, sfm_pairs, num_matched=args.num_covis)
-    sfm_matches = match_features.main(
-        matcher_conf, sfm_pairs, feature_conf["output"], outputs
-    )
-
-    triangulation.main(
-        reference_sfm, sift_sfm, images, sfm_pairs, features, sfm_matches
-    )
-
-    global_descriptors = extract_features.main(retrieval_conf, images, outputs)
-    pairs_from_retrieval.main(
-        global_descriptors,
-        loc_pairs,
-        args.num_loc,
-        query_prefix="query",
-        db_model=reference_sfm,
-    )
-    loc_matches = match_features.main(
-        matcher_conf, loc_pairs, feature_conf["output"], outputs
-    )
-
-    localize_sfm.main(
-        reference_sfm,
-        dataset / "queries/*_time_queries_with_intrinsics.txt",
-        loc_pairs,
-        features,
-        loc_matches,
-        results,
-        covisibility_clustering=False,
-    )  # not required with SuperPoint+SuperGlue
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--dataset",
-        type=Path,
-        default="datasets/aachen",
-        help="Path to the dataset, default: %(default)s",
-    )
-    parser.add_argument(
-        "--outputs",
-        type=Path,
-        default="outputs/aachen",
-        help="Path to the output directory, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_covis",
-        type=int,
-        default=20,
-        help="Number of image pairs for SfM, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_loc",
-        type=int,
-        default=50,
-        help="Number of image pairs for loc, default: %(default)s",
-    )
-    args = parser.parse_args()
-    run(args)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Aachen/README.md hloc/pipelines/Aachen/README.md
--- /tmp/hloc-latest/hloc/pipelines/Aachen/README.md	2026-01-16 16:13:56.814693688 -0700
+++ hloc/pipelines/Aachen/README.md	1969-12-31 17:00:00.000000000 -0700
@@ -1,16 +0,0 @@
-# Aachen-Day-Night dataset
-
-## Installation
-
-Download the dataset from [visuallocalization.net](https://www.visuallocalization.net):
-```bash
-export dataset=datasets/aachen
-wget -r -np -nH -R "index.html*,aachen_v1_1.zip" --cut-dirs=4  https://data.ciirc.cvut.cz/public/projects/2020VisualLocalization/Aachen-Day-Night/ -P $dataset
-unzip $dataset/images/database_and_query_images.zip -d $dataset
-```
-
-## Pipeline
-
-```bash
-python3 -m hloc.pipelines.Aachen.pipeline
-```
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Aachen_v1_1/pipeline_loftr.py hloc/pipelines/Aachen_v1_1/pipeline_loftr.py
--- /tmp/hloc-latest/hloc/pipelines/Aachen_v1_1/pipeline_loftr.py	2026-01-16 16:13:56.814855533 -0700
+++ hloc/pipelines/Aachen_v1_1/pipeline_loftr.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,104 +0,0 @@
-import argparse
-from pathlib import Path
-from pprint import pformat
-
-from ... import (
-    extract_features,
-    localize_sfm,
-    logger,
-    match_dense,
-    pairs_from_covisibility,
-    pairs_from_retrieval,
-    triangulation,
-)
-
-
-def run(args):
-    # Setup the paths
-    dataset = args.dataset
-    images = dataset / "images_upright/"
-    sift_sfm = dataset / "3D-models/aachen_v_1_1"
-
-    outputs = args.outputs  # where everything will be saved
-    outputs.mkdir()
-    reference_sfm = outputs / "sfm_loftr"  # the SfM model we will build
-    sfm_pairs = (
-        outputs / f"pairs-db-covis{args.num_covis}.txt"
-    )  # top-k most covisible in SIFT model
-    loc_pairs = (
-        outputs / f"pairs-query-netvlad{args.num_loc}.txt"
-    )  # top-k retrieved by NetVLAD
-    results = outputs / f"Aachen-v1.1_hloc_loftr_netvlad{args.num_loc}.txt"
-
-    # list the standard configurations available
-    logger.info("Configs for dense feature matchers:\n%s", pformat(match_dense.confs))
-
-    # pick one of the configurations for extraction and matching
-    retrieval_conf = extract_features.confs["netvlad"]
-    matcher_conf = match_dense.confs["loftr_aachen"]
-
-    pairs_from_covisibility.main(sift_sfm, sfm_pairs, num_matched=args.num_covis)
-    features, sfm_matches = match_dense.main(
-        matcher_conf, sfm_pairs, images, outputs, max_kps=8192, overwrite=False
-    )
-
-    triangulation.main(
-        reference_sfm, sift_sfm, images, sfm_pairs, features, sfm_matches
-    )
-
-    global_descriptors = extract_features.main(retrieval_conf, images, outputs)
-    pairs_from_retrieval.main(
-        global_descriptors,
-        loc_pairs,
-        args.num_loc,
-        query_prefix="query",
-        db_model=reference_sfm,
-    )
-    features, loc_matches = match_dense.main(
-        matcher_conf,
-        loc_pairs,
-        images,
-        outputs,
-        features=features,
-        max_kps=None,
-        matches=sfm_matches,
-    )
-
-    localize_sfm.main(
-        reference_sfm,
-        dataset / "queries/*_time_queries_with_intrinsics.txt",
-        loc_pairs,
-        features,
-        loc_matches,
-        results,
-        covisibility_clustering=False,
-    )  # not required with loftr
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--dataset",
-        type=Path,
-        default="datasets/aachen_v1.1",
-        help="Path to the dataset, default: %(default)s",
-    )
-    parser.add_argument(
-        "--outputs",
-        type=Path,
-        default="outputs/aachen_v1.1",
-        help="Path to the output directory, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_covis",
-        type=int,
-        default=20,
-        help="Number of image pairs for SfM, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_loc",
-        type=int,
-        default=50,
-        help="Number of image pairs for loc, default: %(default)s",
-    )
-    args = parser.parse_args()
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Aachen_v1_1/pipeline.py hloc/pipelines/Aachen_v1_1/pipeline.py
--- /tmp/hloc-latest/hloc/pipelines/Aachen_v1_1/pipeline.py	2026-01-16 16:13:56.814855533 -0700
+++ hloc/pipelines/Aachen_v1_1/pipeline.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,104 +0,0 @@
-import argparse
-from pathlib import Path
-from pprint import pformat
-
-from ... import (
-    extract_features,
-    localize_sfm,
-    logger,
-    match_features,
-    pairs_from_covisibility,
-    pairs_from_retrieval,
-    triangulation,
-)
-
-
-def run(args):
-    # Setup the paths
-    dataset = args.dataset
-    images = dataset / "images_upright/"
-    sift_sfm = dataset / "3D-models/aachen_v_1_1"
-
-    outputs = args.outputs  # where everything will be saved
-    reference_sfm = outputs / "sfm_superpoint+superglue"  # the SfM model we will build
-    sfm_pairs = (
-        outputs / f"pairs-db-covis{args.num_covis}.txt"
-    )  # top-k most covisible in SIFT model
-    loc_pairs = (
-        outputs / f"pairs-query-netvlad{args.num_loc}.txt"
-    )  # top-k retrieved by NetVLAD
-    results = (
-        outputs / f"Aachen-v1.1_hloc_superpoint+superglue_netvlad{args.num_loc}.txt"
-    )
-
-    # list the standard configurations available
-    logger.info("Configs for feature extractors:\n%s", pformat(extract_features.confs))
-    logger.info("Configs for feature matchers:\n%s", pformat(match_features.confs))
-
-    # pick one of the configurations for extraction and matching
-    retrieval_conf = extract_features.confs["netvlad"]
-    feature_conf = extract_features.confs["superpoint_max"]
-    matcher_conf = match_features.confs["superglue"]
-
-    features = extract_features.main(feature_conf, images, outputs)
-
-    pairs_from_covisibility.main(sift_sfm, sfm_pairs, num_matched=args.num_covis)
-    sfm_matches = match_features.main(
-        matcher_conf, sfm_pairs, feature_conf["output"], outputs
-    )
-
-    triangulation.main(
-        reference_sfm, sift_sfm, images, sfm_pairs, features, sfm_matches
-    )
-
-    global_descriptors = extract_features.main(retrieval_conf, images, outputs)
-    pairs_from_retrieval.main(
-        global_descriptors,
-        loc_pairs,
-        args.num_loc,
-        query_prefix="query",
-        db_model=reference_sfm,
-    )
-    loc_matches = match_features.main(
-        matcher_conf, loc_pairs, feature_conf["output"], outputs
-    )
-
-    localize_sfm.main(
-        reference_sfm,
-        dataset / "queries/*_time_queries_with_intrinsics.txt",
-        loc_pairs,
-        features,
-        loc_matches,
-        results,
-        covisibility_clustering=False,
-    )  # not required with SuperPoint+SuperGlue
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--dataset",
-        type=Path,
-        default="datasets/aachen_v1.1",
-        help="Path to the dataset, default: %(default)s",
-    )
-    parser.add_argument(
-        "--outputs",
-        type=Path,
-        default="outputs/aachen_v1.1",
-        help="Path to the output directory, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_covis",
-        type=int,
-        default=20,
-        help="Number of image pairs for SfM, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_loc",
-        type=int,
-        default=50,
-        help="Number of image pairs for loc, default: %(default)s",
-    )
-    args = parser.parse_args()
-    run(args)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Aachen_v1_1/README.md hloc/pipelines/Aachen_v1_1/README.md
--- /tmp/hloc-latest/hloc/pipelines/Aachen_v1_1/README.md	2026-01-16 16:13:56.814789152 -0700
+++ hloc/pipelines/Aachen_v1_1/README.md	1969-12-31 17:00:00.000000000 -0700
@@ -1,17 +0,0 @@
-# Aachen-Day-Night dataset v1.1
-
-## Installation
-
-Download the dataset from [visuallocalization.net](https://www.visuallocalization.net):
-```bash
-export dataset=datasets/aachen_v1.1
-wget -r -np -nH -R "index.html*" --cut-dirs=4  https://data.ciirc.cvut.cz/public/projects/2020VisualLocalization/Aachen-Day-Night/ -P $dataset
-unzip $dataset/images/database_and_query_images.zip -d $dataset
-unzip $dataset/aachen_v1_1.zip -d $dataset
-```
-
-## Pipeline
-
-```bash
-python3 -m hloc.pipelines.Aachen_v1_1.pipeline
-```
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Cambridge/pipeline.py hloc/pipelines/Cambridge/pipeline.py
--- /tmp/hloc-latest/hloc/pipelines/Cambridge/pipeline.py	2026-01-16 16:13:56.814993067 -0700
+++ hloc/pipelines/Cambridge/pipeline.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,140 +0,0 @@
-import argparse
-from pathlib import Path
-
-from ... import (
-    extract_features,
-    localize_sfm,
-    logger,
-    match_features,
-    pairs_from_covisibility,
-    pairs_from_retrieval,
-    triangulation,
-)
-from .utils import create_query_list_with_intrinsics, evaluate, scale_sfm_images
-
-SCENES = ["KingsCollege", "OldHospital", "ShopFacade", "StMarysChurch", "GreatCourt"]
-
-
-def run_scene(images, gt_dir, outputs, results, num_covis, num_loc):
-    ref_sfm_sift = gt_dir / "model_train"
-    test_list = gt_dir / "list_query.txt"
-
-    outputs.mkdir(exist_ok=True, parents=True)
-    ref_sfm = outputs / "sfm_superpoint+superglue"
-    ref_sfm_scaled = outputs / "sfm_sift_scaled"
-    query_list = outputs / "query_list_with_intrinsics.txt"
-    sfm_pairs = outputs / f"pairs-db-covis{num_covis}.txt"
-    loc_pairs = outputs / f"pairs-query-netvlad{num_loc}.txt"
-
-    feature_conf = {
-        "output": "feats-superpoint-n4096-r1024",
-        "model": {
-            "name": "superpoint",
-            "nms_radius": 3,
-            "max_keypoints": 4096,
-        },
-        "preprocessing": {
-            "grayscale": True,
-            "resize_max": 1024,
-        },
-    }
-    matcher_conf = match_features.confs["superglue"]
-    retrieval_conf = extract_features.confs["netvlad"]
-
-    create_query_list_with_intrinsics(
-        gt_dir / "empty_all", query_list, test_list, ext=".txt", image_dir=images
-    )
-    with open(test_list, "r") as f:
-        query_seqs = {q.split("/")[0] for q in f.read().rstrip().split("\n")}
-
-    global_descriptors = extract_features.main(retrieval_conf, images, outputs)
-    pairs_from_retrieval.main(
-        global_descriptors,
-        loc_pairs,
-        num_loc,
-        db_model=ref_sfm_sift,
-        query_prefix=query_seqs,
-    )
-
-    features = extract_features.main(feature_conf, images, outputs, as_half=True)
-    pairs_from_covisibility.main(ref_sfm_sift, sfm_pairs, num_matched=num_covis)
-    sfm_matches = match_features.main(
-        matcher_conf, sfm_pairs, feature_conf["output"], outputs
-    )
-
-    scale_sfm_images(ref_sfm_sift, ref_sfm_scaled, images)
-    triangulation.main(
-        ref_sfm, ref_sfm_scaled, images, sfm_pairs, features, sfm_matches
-    )
-
-    loc_matches = match_features.main(
-        matcher_conf, loc_pairs, feature_conf["output"], outputs
-    )
-
-    localize_sfm.main(
-        ref_sfm,
-        query_list,
-        loc_pairs,
-        features,
-        loc_matches,
-        results,
-        covisibility_clustering=False,
-        prepend_camera_name=True,
-    )
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument("--scenes", default=SCENES, choices=SCENES, nargs="+")
-    parser.add_argument("--overwrite", action="store_true")
-    parser.add_argument(
-        "--dataset",
-        type=Path,
-        default="datasets/cambridge",
-        help="Path to the dataset, default: %(default)s",
-    )
-    parser.add_argument(
-        "--outputs",
-        type=Path,
-        default="outputs/cambridge",
-        help="Path to the output directory, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_covis",
-        type=int,
-        default=20,
-        help="Number of image pairs for SfM, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_loc",
-        type=int,
-        default=10,
-        help="Number of image pairs for loc, default: %(default)s",
-    )
-    args = parser.parse_args()
-
-    gt_dirs = args.dataset / "CambridgeLandmarks_Colmap_Retriangulated_1024px"
-
-    all_results = {}
-    for scene in args.scenes:
-        logger.info(f'Working on scene "{scene}".')
-        results = args.outputs / scene / "results.txt"
-        if args.overwrite or not results.exists():
-            run_scene(
-                args.dataset / scene,
-                gt_dirs / scene,
-                args.outputs / scene,
-                results,
-                args.num_covis,
-                args.num_loc,
-            )
-        all_results[scene] = results
-
-    for scene in args.scenes:
-        logger.info(f'Evaluate scene "{scene}".')
-        evaluate(
-            gt_dirs / scene / "empty_all",
-            all_results[scene],
-            gt_dirs / scene / "list_query.txt",
-            ext=".txt",
-        )
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Cambridge/README.md hloc/pipelines/Cambridge/README.md
--- /tmp/hloc-latest/hloc/pipelines/Cambridge/README.md	2026-01-16 16:13:56.814919017 -0700
+++ hloc/pipelines/Cambridge/README.md	1969-12-31 17:00:00.000000000 -0700
@@ -1,47 +0,0 @@
-# Cambridge Landmarks dataset
-
-## Installation
-
-Download the dataset from the [PoseNet project page](http://mi.eng.cam.ac.uk/projects/relocalisation/):
-```bash
-export dataset=datasets/cambridge
-export scenes=( "KingsCollege" "OldHospital" "StMarysChurch" "ShopFacade" "GreatCourt" )
-export IDs=( "251342" "251340" "251294" "251336" "251291" )
-for i in "${!scenes[@]}"; do
-wget https://www.repository.cam.ac.uk/bitstream/handle/1810/${IDs[i]}/${scenes[i]}.zip -P $dataset \
-&& unzip $dataset/${scenes[i]}.zip -d $dataset && rm $dataset/${scenes[i]}.zip; done
-```
-
-Download the SIFT SfM models, courtesy of Torsten Sattler:
-```bash
-export fileid=1esqzZ1zEQlzZVic-H32V6kkZvc4NeS15
-export filename=$dataset/CambridgeLandmarks_Colmap_Retriangulated_1024px.zip
-wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate "https://docs.google.com/uc?export=download&id=$fileid" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=$fileid" -O $filename && rm -rf /tmp/cookies.txt
-unzip $filename -d $dataset
-```
-
-## Pipeline
-
-```bash
-python3 -m hloc.pipelines.Cambridge.pipeline
-```
-
-## Results
-We report the median error in translation/rotation in cm/deg over all scenes:
-| Method \ Scene           | Court           | King's          | Hospital        | Shop           | St. Mary's     |
-| ------------------------ | --------------- | --------------- | --------------- | -------------- | -------------- |
-| Active Search            | 24/0.13         | 13/0.22         | 20/0.36         | **4**/0.21     | 8/0.25         |
-| DSAC*                    | 49/0.3          | 15/0.3          | 21/0.4          | 5/0.3          | 13/0.4         |
-| **SuperPoint+SuperGlue** | **17**/**0.11** | **12**/**0.21** | **14**/**0.30** | **4**/**0.19** | **7**/**0.22** |
-
-## Citation
-
-Please cite the following paper if you use the Cambridge Landmarks dataset:
-```
-@inproceedings{kendall2015posenet,
-  title={{PoseNet}: A convolutional network for real-time {6-DoF} camera relocalization},
-  author={Kendall, Alex and Grimes, Matthew and Cipolla, Roberto},
-  booktitle={ICCV},
-  year={2015}
-}
-```
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/Cambridge/utils.py hloc/pipelines/Cambridge/utils.py
--- /tmp/hloc-latest/hloc/pipelines/Cambridge/utils.py	2026-01-16 16:13:56.814993067 -0700
+++ hloc/pipelines/Cambridge/utils.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,145 +0,0 @@
-import logging
-
-import cv2
-import numpy as np
-
-from hloc.utils.read_write_model import (
-    qvec2rotmat,
-    read_cameras_binary,
-    read_cameras_text,
-    read_images_binary,
-    read_images_text,
-    read_model,
-    write_model,
-)
-
-logger = logging.getLogger(__name__)
-
-
-def scale_sfm_images(full_model, scaled_model, image_dir):
-    """Duplicate the provided model and scale the camera intrinsics so that
-    they match the original image resolution - makes everything easier.
-    """
-    logger.info("Scaling the COLMAP model to the original image size.")
-    scaled_model.mkdir(exist_ok=True)
-    cameras, images, points3D = read_model(full_model)
-
-    scaled_cameras = {}
-    for id_, image in images.items():
-        name = image.name
-        img = cv2.imread(str(image_dir / name))
-        assert img is not None, image_dir / name
-        h, w = img.shape[:2]
-
-        cam_id = image.camera_id
-        if cam_id in scaled_cameras:
-            assert scaled_cameras[cam_id].width == w
-            assert scaled_cameras[cam_id].height == h
-            continue
-
-        camera = cameras[cam_id]
-        assert camera.model == "SIMPLE_RADIAL"
-        sx = w / camera.width
-        sy = h / camera.height
-        assert sx == sy, (sx, sy)
-        scaled_cameras[cam_id] = camera._replace(
-            width=w, height=h, params=camera.params * np.array([sx, sx, sy, 1.0])
-        )
-
-    write_model(scaled_cameras, images, points3D, scaled_model)
-
-
-def create_query_list_with_intrinsics(
-    model, out, list_file=None, ext=".bin", image_dir=None
-):
-    """Create a list of query images with intrinsics from the colmap model."""
-    if ext == ".bin":
-        images = read_images_binary(model / "images.bin")
-        cameras = read_cameras_binary(model / "cameras.bin")
-    else:
-        images = read_images_text(model / "images.txt")
-        cameras = read_cameras_text(model / "cameras.txt")
-
-    name2id = {image.name: i for i, image in images.items()}
-    if list_file is None:
-        names = list(name2id)
-    else:
-        with open(list_file, "r") as f:
-            names = f.read().rstrip().split("\n")
-    data = []
-    for name in names:
-        image = images[name2id[name]]
-        camera = cameras[image.camera_id]
-        w, h, params = camera.width, camera.height, camera.params
-
-        if image_dir is not None:
-            # Check the original image size and rescale the camera intrinsics
-            img = cv2.imread(str(image_dir / name))
-            assert img is not None, image_dir / name
-            h_orig, w_orig = img.shape[:2]
-            assert camera.model == "SIMPLE_RADIAL"
-            sx = w_orig / w
-            sy = h_orig / h
-            assert sx == sy, (sx, sy)
-            w, h = w_orig, h_orig
-            params = params * np.array([sx, sx, sy, 1.0])
-
-        p = [name, camera.model, w, h] + params.tolist()
-        data.append(" ".join(map(str, p)))
-    with open(out, "w") as f:
-        f.write("\n".join(data))
-
-
-def evaluate(model, results, list_file=None, ext=".bin", only_localized=False):
-    predictions = {}
-    with open(results, "r") as f:
-        for data in f.read().rstrip().split("\n"):
-            data = data.split()
-            name = data[0]
-            q, t = np.split(np.array(data[1:], float), [4])
-            predictions[name] = (qvec2rotmat(q), t)
-    if ext == ".bin":
-        images = read_images_binary(model / "images.bin")
-    else:
-        images = read_images_text(model / "images.txt")
-    name2id = {image.name: i for i, image in images.items()}
-
-    if list_file is None:
-        test_names = list(name2id)
-    else:
-        with open(list_file, "r") as f:
-            test_names = f.read().rstrip().split("\n")
-
-    errors_t = []
-    errors_R = []
-    for name in test_names:
-        if name not in predictions:
-            if only_localized:
-                continue
-            e_t = np.inf
-            e_R = 180.0
-        else:
-            image = images[name2id[name]]
-            R_gt, t_gt = image.qvec2rotmat(), image.tvec
-            R, t = predictions[name]
-            e_t = np.linalg.norm(-R_gt.T @ t_gt + R.T @ t, axis=0)
-            cos = np.clip((np.trace(np.dot(R_gt.T, R)) - 1) / 2, -1.0, 1.0)
-            e_R = np.rad2deg(np.abs(np.arccos(cos)))
-        errors_t.append(e_t)
-        errors_R.append(e_R)
-
-    errors_t = np.array(errors_t)
-    errors_R = np.array(errors_R)
-
-    med_t = np.median(errors_t)
-    med_R = np.median(errors_R)
-    out = f"Results for file {results.name}:"
-    out += f"\nMedian errors: {med_t:.3f}m, {med_R:.3f}deg"
-
-    out += "\nPercentage of test images localized within:"
-    threshs_t = [0.01, 0.02, 0.03, 0.05, 0.25, 0.5, 5.0]
-    threshs_R = [1.0, 2.0, 3.0, 5.0, 2.0, 5.0, 10.0]
-    for th_t, th_R in zip(threshs_t, threshs_R):
-        ratio = np.mean((errors_t < th_t) & (errors_R < th_R))
-        out += f"\n\t{th_t*100:.0f}cm, {th_R:.0f}deg : {ratio*100:.2f}%"
-    logger.info(out)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/CMU/pipeline.py hloc/pipelines/CMU/pipeline.py
--- /tmp/hloc-latest/hloc/pipelines/CMU/pipeline.py	2026-01-16 16:13:56.814919017 -0700
+++ hloc/pipelines/CMU/pipeline.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,133 +0,0 @@
-import argparse
-from pathlib import Path
-
-from ... import (
-    extract_features,
-    localize_sfm,
-    logger,
-    match_features,
-    pairs_from_covisibility,
-    pairs_from_retrieval,
-    triangulation,
-)
-
-TEST_SLICES = [2, 3, 4, 5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21]
-
-
-def generate_query_list(dataset, path, slice_):
-    cameras = {}
-    with open(dataset / "intrinsics.txt", "r") as f:
-        for line in f.readlines():
-            if line[0] == "#" or line == "\n":
-                continue
-            data = line.split()
-            cameras[data[0]] = data[1:]
-    assert len(cameras) == 2
-
-    queries = dataset / f"{slice_}/test-images-{slice_}.txt"
-    with open(queries, "r") as f:
-        queries = [q.rstrip("\n") for q in f.readlines()]
-
-    out = [[q] + cameras[q.split("_")[2]] for q in queries]
-    with open(path, "w") as f:
-        f.write("\n".join(map(" ".join, out)))
-
-
-def run_slice(slice_, root, outputs, num_covis, num_loc):
-    dataset = root / slice_
-    ref_images = dataset / "database"
-    query_images = dataset / "query"
-    sift_sfm = dataset / "sparse"
-
-    outputs = outputs / slice_
-    outputs.mkdir(exist_ok=True, parents=True)
-    query_list = dataset / "queries_with_intrinsics.txt"
-    sfm_pairs = outputs / f"pairs-db-covis{num_covis}.txt"
-    loc_pairs = outputs / f"pairs-query-netvlad{num_loc}.txt"
-    ref_sfm = outputs / "sfm_superpoint+superglue"
-    results = outputs / f"CMU_hloc_superpoint+superglue_netvlad{num_loc}.txt"
-
-    # pick one of the configurations for extraction and matching
-    retrieval_conf = extract_features.confs["netvlad"]
-    feature_conf = extract_features.confs["superpoint_aachen"]
-    matcher_conf = match_features.confs["superglue"]
-
-    pairs_from_covisibility.main(sift_sfm, sfm_pairs, num_matched=num_covis)
-    features = extract_features.main(feature_conf, ref_images, outputs, as_half=True)
-    sfm_matches = match_features.main(
-        matcher_conf, sfm_pairs, feature_conf["output"], outputs
-    )
-    triangulation.main(ref_sfm, sift_sfm, ref_images, sfm_pairs, features, sfm_matches)
-
-    generate_query_list(root, query_list, slice_)
-    global_descriptors = extract_features.main(retrieval_conf, ref_images, outputs)
-    global_descriptors = extract_features.main(retrieval_conf, query_images, outputs)
-    pairs_from_retrieval.main(
-        global_descriptors, loc_pairs, num_loc, query_list=query_list, db_model=ref_sfm
-    )
-
-    features = extract_features.main(feature_conf, query_images, outputs, as_half=True)
-    loc_matches = match_features.main(
-        matcher_conf, loc_pairs, feature_conf["output"], outputs
-    )
-
-    localize_sfm.main(
-        ref_sfm,
-        dataset / "queries/*_time_queries_with_intrinsics.txt",
-        loc_pairs,
-        features,
-        loc_matches,
-        results,
-    )
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--slices",
-        type=str,
-        default="*",
-        help="a single number, an interval (e.g. 2-6), "
-        "or a Python-style list or int (e.g. [2, 3, 4]",
-    )
-    parser.add_argument(
-        "--dataset",
-        type=Path,
-        default="datasets/cmu_extended",
-        help="Path to the dataset, default: %(default)s",
-    )
-    parser.add_argument(
-        "--outputs",
-        type=Path,
-        default="outputs/aachen_extended",
-        help="Path to the output directory, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_covis",
-        type=int,
-        default=20,
-        help="Number of image pairs for SfM, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_loc",
-        type=int,
-        default=10,
-        help="Number of image pairs for loc, default: %(default)s",
-    )
-    args = parser.parse_args()
-
-    if args.slice == "*":
-        slices = TEST_SLICES
-    if "-" in args.slices:
-        min_, max_ = args.slices.split("-")
-        slices = list(range(int(min_), int(max_) + 1))
-    else:
-        slices = eval(args.slices)
-        if isinstance(slices, int):
-            slices = [slices]
-
-    for slice_ in slices:
-        logger.info("Working on slice %s.", slice_)
-        run_slice(
-            f"slice{slice_}", args.dataset, args.outputs, args.num_covis, args.num_loc
-        )
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/CMU/README.md hloc/pipelines/CMU/README.md
--- /tmp/hloc-latest/hloc/pipelines/CMU/README.md	2026-01-16 16:13:56.814855533 -0700
+++ hloc/pipelines/CMU/README.md	1969-12-31 17:00:00.000000000 -0700
@@ -1,16 +0,0 @@
-# Extended CMU Seasons dataset
-
-## Installation
-
-Download the dataset from [visuallocalization.net](https://www.visuallocalization.net):
-```bash
-export dataset=datasets/cmu_extended
-wget -r -np -nH -R "index.html*" --cut-dirs=4  https://data.ciirc.cvut.cz/public/projects/2020VisualLocalization/Extended-CMU-Seasons/ -P $dataset
-for slice in $dataset/*.tar; do tar -xf $slice -C $dataset && rm $slice; done
-```
-
-## Pipeline
-
-```bash
-python3 -m hloc.pipelines.CMU.pipeline
-```
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/RobotCar/colmap_from_nvm.py hloc/pipelines/RobotCar/colmap_from_nvm.py
--- /tmp/hloc-latest/hloc/pipelines/RobotCar/colmap_from_nvm.py	2026-01-16 16:13:56.815082664 -0700
+++ hloc/pipelines/RobotCar/colmap_from_nvm.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,176 +0,0 @@
-import argparse
-import logging
-import sqlite3
-from collections import defaultdict
-from pathlib import Path
-
-import numpy as np
-from tqdm import tqdm
-
-from ...colmap_from_nvm import (
-    camera_center_to_translation,
-    recover_database_images_and_ids,
-)
-from ...utils.read_write_model import (
-    CAMERA_MODEL_IDS,
-    Camera,
-    Image,
-    Point3D,
-    write_model,
-)
-
-logger = logging.getLogger(__name__)
-
-
-def read_nvm_model(nvm_path, database_path, image_ids, camera_ids, skip_points=False):
-    # Extract the intrinsics from the db file instead of the NVM model
-    db = sqlite3.connect(str(database_path))
-    ret = db.execute("SELECT camera_id, model, width, height, params FROM cameras;")
-    cameras = {}
-    for camera_id, camera_model, width, height, params in ret:
-        params = np.fromstring(params, dtype=np.double).reshape(-1)
-        camera_model = CAMERA_MODEL_IDS[camera_model]
-        assert len(params) == camera_model.num_params, (
-            len(params),
-            camera_model.num_params,
-        )
-        camera = Camera(
-            id=camera_id,
-            model=camera_model.model_name,
-            width=int(width),
-            height=int(height),
-            params=params,
-        )
-        cameras[camera_id] = camera
-
-    nvm_f = open(nvm_path, "r")
-    line = nvm_f.readline()
-    while line == "\n" or line.startswith("NVM_V3"):
-        line = nvm_f.readline()
-    num_images = int(line)
-    # assert num_images == len(cameras), (num_images, len(cameras))
-
-    logger.info(f"Reading {num_images} images...")
-    image_idx_to_db_image_id = []
-    image_data = []
-    i = 0
-    while i < num_images:
-        line = nvm_f.readline()
-        if line == "\n":
-            continue
-        data = line.strip("\n").lstrip("./").split(" ")
-        image_data.append(data)
-        image_idx_to_db_image_id.append(image_ids[data[0]])
-        i += 1
-
-    line = nvm_f.readline()
-    while line == "\n":
-        line = nvm_f.readline()
-    num_points = int(line)
-
-    if skip_points:
-        logger.info(f"Skipping {num_points} points.")
-        num_points = 0
-    else:
-        logger.info(f"Reading {num_points} points...")
-    points3D = {}
-    image_idx_to_keypoints = defaultdict(list)
-    i = 0
-    pbar = tqdm(total=num_points, unit="pts")
-    while i < num_points:
-        line = nvm_f.readline()
-        if line == "\n":
-            continue
-
-        data = line.strip("\n").split(" ")
-        x, y, z, r, g, b, num_observations = data[:7]
-        obs_image_ids, point2D_idxs = [], []
-        for j in range(int(num_observations)):
-            s = 7 + 4 * j
-            img_index, kp_index, kx, ky = data[s : s + 4]
-            image_idx_to_keypoints[int(img_index)].append(
-                (int(kp_index), float(kx), float(ky), i)
-            )
-            db_image_id = image_idx_to_db_image_id[int(img_index)]
-            obs_image_ids.append(db_image_id)
-            point2D_idxs.append(kp_index)
-
-        point = Point3D(
-            id=i,
-            xyz=np.array([x, y, z], float),
-            rgb=np.array([r, g, b], int),
-            error=1.0,  # fake
-            image_ids=np.array(obs_image_ids, int),
-            point2D_idxs=np.array(point2D_idxs, int),
-        )
-        points3D[i] = point
-
-        i += 1
-        pbar.update(1)
-    pbar.close()
-
-    logger.info("Parsing image data...")
-    images = {}
-    for i, data in enumerate(image_data):
-        # Skip the focal length. Skip the distortion and terminal 0.
-        name, _, qw, qx, qy, qz, cx, cy, cz, _, _ = data
-        qvec = np.array([qw, qx, qy, qz], float)
-        c = np.array([cx, cy, cz], float)
-        t = camera_center_to_translation(c, qvec)
-
-        if i in image_idx_to_keypoints:
-            # NVM only stores triangulated 2D keypoints: add dummy ones
-            keypoints = image_idx_to_keypoints[i]
-            point2D_idxs = np.array([d[0] for d in keypoints])
-            tri_xys = np.array([[x, y] for _, x, y, _ in keypoints])
-            tri_ids = np.array([i for _, _, _, i in keypoints])
-
-            num_2Dpoints = max(point2D_idxs) + 1
-            xys = np.zeros((num_2Dpoints, 2), float)
-            point3D_ids = np.full(num_2Dpoints, -1, int)
-            xys[point2D_idxs] = tri_xys
-            point3D_ids[point2D_idxs] = tri_ids
-        else:
-            xys = np.zeros((0, 2), float)
-            point3D_ids = np.full(0, -1, int)
-
-        image_id = image_ids[name]
-        image = Image(
-            id=image_id,
-            qvec=qvec,
-            tvec=t,
-            camera_id=camera_ids[name],
-            name=name.replace("png", "jpg"),  # some hack required for RobotCar
-            xys=xys,
-            point3D_ids=point3D_ids,
-        )
-        images[image_id] = image
-
-    return cameras, images, points3D
-
-
-def main(nvm, database, output, skip_points=False):
-    assert nvm.exists(), nvm
-    assert database.exists(), database
-
-    image_ids, camera_ids = recover_database_images_and_ids(database)
-
-    logger.info("Reading the NVM model...")
-    model = read_nvm_model(
-        nvm, database, image_ids, camera_ids, skip_points=skip_points
-    )
-
-    logger.info("Writing the COLMAP model...")
-    output.mkdir(exist_ok=True, parents=True)
-    write_model(*model, path=str(output), ext=".bin")
-    logger.info("Done.")
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument("--nvm", required=True, type=Path)
-    parser.add_argument("--database", required=True, type=Path)
-    parser.add_argument("--output", required=True, type=Path)
-    parser.add_argument("--skip_points", action="store_true")
-    args = parser.parse_args()
-    main(**args.__dict__)
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/RobotCar/pipeline.py hloc/pipelines/RobotCar/pipeline.py
--- /tmp/hloc-latest/hloc/pipelines/RobotCar/pipeline.py	2026-01-16 16:13:56.815082664 -0700
+++ hloc/pipelines/RobotCar/pipeline.py	1969-12-31 17:00:00.000000000 -0700
@@ -1,143 +0,0 @@
-import argparse
-import glob
-from pathlib import Path
-
-from ... import (
-    extract_features,
-    localize_sfm,
-    match_features,
-    pairs_from_covisibility,
-    pairs_from_retrieval,
-    triangulation,
-)
-from . import colmap_from_nvm
-
-CONDITIONS = [
-    "dawn",
-    "dusk",
-    "night",
-    "night-rain",
-    "overcast-summer",
-    "overcast-winter",
-    "rain",
-    "snow",
-    "sun",
-]
-
-
-def generate_query_list(dataset, image_dir, path):
-    h, w = 1024, 1024
-    intrinsics_filename = "intrinsics/{}_intrinsics.txt"
-    cameras = {}
-    for side in ["left", "right", "rear"]:
-        with open(dataset / intrinsics_filename.format(side), "r") as f:
-            fx = f.readline().split()[1]
-            fy = f.readline().split()[1]
-            cx = f.readline().split()[1]
-            cy = f.readline().split()[1]
-            assert fx == fy
-            params = ["SIMPLE_RADIAL", w, h, fx, cx, cy, 0.0]
-            cameras[side] = [str(p) for p in params]
-
-    queries = glob.glob((image_dir / "**/*.jpg").as_posix(), recursive=True)
-    queries = [
-        Path(q).relative_to(image_dir.parents[0]).as_posix() for q in sorted(queries)
-    ]
-
-    out = [[q] + cameras[Path(q).parent.name] for q in queries]
-    with open(path, "w") as f:
-        f.write("\n".join(map(" ".join, out)))
-
-
-def run(args):
-    # Setup the paths
-    dataset = args.dataset
-    images = dataset / "images/"
-
-    outputs = args.outputs  # where everything will be saved
-    outputs.mkdir(exist_ok=True, parents=True)
-    query_list = outputs / "{condition}_queries_with_intrinsics.txt"
-    sift_sfm = outputs / "sfm_sift"
-    reference_sfm = outputs / "sfm_superpoint+superglue"
-    sfm_pairs = outputs / f"pairs-db-covis{args.num_covis}.txt"
-    loc_pairs = outputs / f"pairs-query-netvlad{args.num_loc}.txt"
-    results = outputs / f"RobotCar_hloc_superpoint+superglue_netvlad{args.num_loc}.txt"
-
-    # pick one of the configurations for extraction and matching
-    retrieval_conf = extract_features.confs["netvlad"]
-    feature_conf = extract_features.confs["superpoint_aachen"]
-    matcher_conf = match_features.confs["superglue"]
-
-    for condition in CONDITIONS:
-        generate_query_list(
-            dataset, images / condition, str(query_list).format(condition=condition)
-        )
-
-    features = extract_features.main(feature_conf, images, outputs, as_half=True)
-
-    colmap_from_nvm.main(
-        dataset / "3D-models/all-merged/all.nvm",
-        dataset / "3D-models/overcast-reference.db",
-        sift_sfm,
-    )
-    pairs_from_covisibility.main(sift_sfm, sfm_pairs, num_matched=args.num_covis)
-    sfm_matches = match_features.main(
-        matcher_conf, sfm_pairs, feature_conf["output"], outputs
-    )
-
-    triangulation.main(
-        reference_sfm, sift_sfm, images, sfm_pairs, features, sfm_matches
-    )
-
-    global_descriptors = extract_features.main(retrieval_conf, images, outputs)
-    # TODO: do per location and per camera
-    pairs_from_retrieval.main(
-        global_descriptors,
-        loc_pairs,
-        args.num_loc,
-        query_prefix=CONDITIONS,
-        db_model=reference_sfm,
-    )
-    loc_matches = match_features.main(
-        matcher_conf, loc_pairs, feature_conf["output"], outputs
-    )
-
-    localize_sfm.main(
-        reference_sfm,
-        Path(str(query_list).format(condition="*")),
-        loc_pairs,
-        features,
-        loc_matches,
-        results,
-        covisibility_clustering=False,
-        prepend_camera_name=True,
-    )
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--dataset",
-        type=Path,
-        default="datasets/robotcar",
-        help="Path to the dataset, default: %(default)s",
-    )
-    parser.add_argument(
-        "--outputs",
-        type=Path,
-        default="outputs/robotcar",
-        help="Path to the output directory, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_covis",
-        type=int,
-        default=20,
-        help="Number of image pairs for SfM, default: %(default)s",
-    )
-    parser.add_argument(
-        "--num_loc",
-        type=int,
-        default=20,
-        help="Number of image pairs for loc, default: %(default)s",
-    )
-    args = parser.parse_args()
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/RobotCar/README.md hloc/pipelines/RobotCar/README.md
--- /tmp/hloc-latest/hloc/pipelines/RobotCar/README.md	2026-01-16 16:13:56.814993067 -0700
+++ hloc/pipelines/RobotCar/README.md	1969-12-31 17:00:00.000000000 -0700
@@ -1,16 +0,0 @@
-# RobotCar Seasons dataset
-
-## Installation
-
-Download the dataset from [visuallocalization.net](https://www.visuallocalization.net):
-```bash
-export dataset=datasets/robotcar
-wget -r -np -nH -R "index.html*" --cut-dirs=4  https://data.ciirc.cvut.cz/public/projects/2020VisualLocalization/RobotCar-Seasons/ -P $dataset
-for condition in $dataset/images/*.zip; do unzip condition -d $dataset/images/; done
-```
-
-## Pipeline
-
-```bash
-python3 -m hloc.pipelines.RobotCar.pipeline
-```
diff -Naur '--exclude=__pycache__' '--exclude=*.pyc' '--exclude=SceneScape' /tmp/hloc-latest/hloc/pipelines/utils.py hloc/pipelines/utils.py
--- /tmp/hloc-latest/hloc/pipelines/utils.py	1969-12-31 17:00:00.000000000 -0700
+++ hloc/pipelines/utils.py	2026-01-16 16:16:08.558653868 -0700
@@ -0,0 +1,42 @@
+# SPDX-FileCopyrightText: (C) 2025 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
+
+"""Example:
+python -m hloc.pipelines.utils --dataset_dir datasets/inloc/
+"""
+import argparse
+import csv
+from pathlib import Path
+from scipy.spatial.transform import Rotation as R
+from ..localize_inloc import get_scan_pose
+
+
+def get_database_pose(dataset_dir, rpath):
+  """Get pose for image rpath in dataset_dir using alignment txt files and
+  image azimuth and elevation.
+
+  Returns:
+      q_wxyz, tvec
+  """
+  rpath = str(rpath)
+  Tr = get_scan_pose(dataset_dir, rpath)
+  parts = rpath.split("_")
+  az = float(parts[-2])
+  el = float(parts[-1].split(".")[0])
+  # camera pose: camera -> world
+  cam_pose = R.from_euler("zy", ((az, el),), degrees=True).inv()
+  quat = (R.from_matrix(Tr[:3, :3]) * cam_pose).as_quat()
+  quat[0], quat[3] = quat[3], quat[0]  # xyzw -> wxyz
+  return quat, Tr[:3, -1:]
+
+
+if __name__ == "__main__":
+  parser = argparse.ArgumentParser()
+  parser.add_argument("--dataset_dir", type=Path, required=True)
+  args = parser.parse_args()
+  with open(args.dataset_dir / "dataset_poses.csv", "w", newline="") as dpfile:
+    dpfile.write("#filename qw qx qy qz tx ty tz\n")
+    csv_dp = csv.writer(dpfile, delimiter=" ", lineterminator="\n")
+    for rpath in sorted(args.dataset_dir.glob("database/cutouts/*/*/*.jpg")):
+      quat, trans = get_database_pose(args.dataset_dir, rpath)
+      csv_dp.writerow([rpath] + quat.ravel().tolist() + trans.ravel().tolist())
